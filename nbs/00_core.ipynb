{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The foundations\n",
    "\n",
    "> Let's try to replicate the standard usage of MNL frameworks\n",
    "\n",
    "We will try to implement a basic MNL package to compare against biogeme/others... let's start from this [blog post](https://aaronkub.com/2020/02/12/logistic-regression-with-pytorch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grab some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Iris.csv\").drop(\"Id\", axis=1)\n",
    "\n",
    "X_numpy = data.drop(\"Species\", axis=1).values\n",
    "\n",
    "target_map = {\n",
    "    val: index for index, val in enumerate(data.Species.unique())\n",
    "}\n",
    "y_numpy = data.Species.map(target_map).values\n",
    "\n",
    "X = torch.tensor(X_numpy, dtype=torch.float32)\n",
    "y = torch.tensor(y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_data(data, x_cols=None, target_col=None):\n",
    "    \"This is far from optimal, as we shu=ould be reading values lazily\"\n",
    "    target_col = ifnone(target_col, list(data.columns)[-1])\n",
    "    x_cols = [col for col in ifnone(x_cols, list(data.columns)) if col!=target_col]\n",
    "    print(f'{x_cols=},\\n{target_col=}')\n",
    "    X_numpy = data.loc[:, x_cols].values\n",
    "    target_map = {\n",
    "        val: index for index, val in enumerate(data.loc[:,target_col].unique())\n",
    "    }\n",
    "    y_numpy = data.loc[:,target_col].map(target_map).values\n",
    "    \n",
    "    X = torch.tensor(X_numpy, dtype=torch.float32)\n",
    "    y = torch.tensor(y_numpy)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_cols=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'],\n",
      "target_col='Species'\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
       "         [4.9000, 3.0000, 1.4000, 0.2000],\n",
       "         [4.7000, 3.2000, 1.3000, 0.2000],\n",
       "         [4.6000, 3.1000, 1.5000, 0.2000],\n",
       "         [5.0000, 3.6000, 1.4000, 0.2000]]),\n",
       " tensor([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5], y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(range_of(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_valid_split(X, y, pct=0.2, shuffle=True):\n",
    "    assert len(X) == len(y), \"X and y don't have the same number of elements\"\n",
    "    indices = range_of(X)\n",
    "    if shuffle:\n",
    "        random.shuffle(indices)\n",
    "    n = len(X)\n",
    "    n_train = int(n * (1-0.2))\n",
    "    X_train, y_train = X[indices[:n_train]], y[indices[:n_train]]\n",
    "    X_valid, y_valid = X[indices[n_train:]], y[indices[n_train:]]\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = L([0,1,2,3,4,5,6,7,8,9])\n",
    "_y = L('a,b,c,d,e,f,g,h,i,j'.split(','))\n",
    "\n",
    "test_eq(train_valid_split(_X,_y, shuffle=False)[0], [0,1,2,3,4,5,6,7])\n",
    "test_eq(train_valid_split(_X,_y, shuffle=False)[3], ['i','j'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearMNL(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim=4, out_dim=5, bias=False):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.linear = nn.Linear(in_dim, out_dim, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearMNL(4,3)\n",
    "x = torch.rand(10,4)\n",
    "\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoaders:\n",
    "    \"\"\"\n",
    "    A class to store dataloaders (train/valid/test....)\"\"\"\n",
    "    def __init__(self, train_dl, valid_dl=None):\n",
    "        store_attr()\n",
    "        \n",
    "    def one_batch(self, dl=None):\n",
    "        dl = ifnone(dl, self.dl_train)\n",
    "        return next(iter(dl))\n",
    "    \n",
    "    @delegates(DataLoader, but='batch_size')\n",
    "    @classmethod\n",
    "    def from_datasets(cls, train_ds, valid_ds=None, batch_size=1, **kwargs):\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, **kwargs)\n",
    "        if valid_ds is not None:\n",
    "            valid_dl = DataLoader(valid_ds, batch_size=2*batch_size, **kwargs)\n",
    "        else:\n",
    "            valid_dl = None\n",
    "        return cls(train_dl, valid_dl)\n",
    "    \n",
    "    @delegates(DataLoader, but='batch_size')\n",
    "    @classmethod\n",
    "    def from_Xy(cls, X, y, pct=None, batch_size=1, **kwargs):\n",
    "        if pct is not None:\n",
    "            X_train, y_train, X_valid, y_valid = train_valid_split(X, y, pct)\n",
    "        else:\n",
    "            X_train, y_train, X_valid, y_valid = X, y, None, None\n",
    "        train_ds = TensorDataset(X_train, y_train)\n",
    "        if X_valid is not None:\n",
    "            valid_ds = TensorDataset(X_valid, y_valid)\n",
    "        else:\n",
    "            valid_ds = None\n",
    "        return cls.from_datasets(train_ds, valid_ds, batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_Xy(X, y, pct=0.2, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Learner:\n",
    "    \"A wrapper around dls, model and optimizer\"\n",
    "    def __init__(self, dls, model, loss_func=torch.nn.CrossEntropyLoss()):\n",
    "        store_attr()\n",
    "        \n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        for batch, (x, y) in enumerate(self.dls.train_dl):\n",
    "            pred = self.model(x)  # 1\n",
    "            loss = self.loss_func(pred, y)\n",
    "\n",
    "            #backprop\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss\n",
    "    \n",
    "    def validate(self, dl=None):\n",
    "        dl = ifnone(dl, self.dls.valid_dl)\n",
    "        if (dl is None):\n",
    "            return 'No validation data'\n",
    "        val_loss, accu = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (x, y) in enumerate(dl):\n",
    "                pred = self.model(x)\n",
    "                val_loss += self.loss_func(pred, y).item()\n",
    "                accu += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        return val_loss, accu / len(dl.dataset)\n",
    "    \n",
    "    def fit(self, n_epochs=10, lr=0.01, wd=0.01):\n",
    "        \n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(), \n",
    "            lr=lr, \n",
    "            weight_decay=wd\n",
    "        )\n",
    "        \n",
    "        for epoch in progress_bar(range_of(n_epochs)):\n",
    "            loss = self.train_one_epoch()\n",
    "            val_loss, accuracy = self.validate()\n",
    "            print(f'epoch = {epoch:3.0f}, val_loss = {val_loss:.3f}, accuracy = {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearMNL(4,3)\n",
    "learn = Learner(dls, model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20/20 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =   0, val_loss = 1.581, accuracy = 0.90\n",
      "epoch =   1, val_loss = 1.494, accuracy = 0.93\n",
      "epoch =   2, val_loss = 1.431, accuracy = 0.93\n",
      "epoch =   3, val_loss = 1.377, accuracy = 0.93\n",
      "epoch =   4, val_loss = 1.331, accuracy = 0.93\n",
      "epoch =   5, val_loss = 1.291, accuracy = 0.93\n",
      "epoch =   6, val_loss = 1.255, accuracy = 0.93\n",
      "epoch =   7, val_loss = 1.224, accuracy = 0.93\n",
      "epoch =   8, val_loss = 1.196, accuracy = 0.93\n",
      "epoch =   9, val_loss = 1.171, accuracy = 0.93\n",
      "epoch =  10, val_loss = 1.148, accuracy = 0.97\n",
      "epoch =  11, val_loss = 1.127, accuracy = 0.97\n",
      "epoch =  12, val_loss = 1.108, accuracy = 1.00\n",
      "epoch =  13, val_loss = 1.090, accuracy = 1.00\n",
      "epoch =  14, val_loss = 1.074, accuracy = 1.00\n",
      "epoch =  15, val_loss = 1.058, accuracy = 1.00\n",
      "epoch =  16, val_loss = 1.044, accuracy = 1.00\n",
      "epoch =  17, val_loss = 1.031, accuracy = 1.00\n",
      "epoch =  18, val_loss = 1.018, accuracy = 1.00\n",
      "epoch =  19, val_loss = 1.006, accuracy = 1.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
